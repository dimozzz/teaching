Alice was told a value of a random variable $\alpha$, and Bob was told a value of some function
$f(\alpha)$. Design an algorithm which allows Alice to tell Bob the value of $\alpha$, using on average
no more that $\entropy(\alpha \mid f(\alpha)) + 1$ bits.
