\section{Применения колмогоровской сложности}

Колмогоровская сложность применяется в задачах, связанных с попытками доказать или опровергнуть
$\NP$-полноту задачи $\langcplx{MCSP}$, в которой по таблице истинности функции $f\colon \{0, 1\}^n
\to \{0, 1\}$ и числу $s < 2^n$ необходимо определить, существует ли булева схема размера $s$, которая
считает данную функцию. Нетрудно понять, что эта задача принадлежит классу $\NP$. Но не доказано,
является ли эта задача $\NP$-полной.  

Рассмотрим более простую задачу. Обозначим за $L_k$ множество языков, принимаемых детерминированными
автоматами с одной лентой и $k$ головками на ней, причём головки едут только в одну сторону. 

\begin{proposition}
    $L_{k + 1} \nsubseteq L_{k}$.
\end{proposition}

\begin{proof}
    Рассмотрим язык $L$, состоящий из строк вида:
    $$
        w_1\#w_2\#\ldots \#w_{m - 1}\#w_m\#w_m\#w_{m - 1}\#\ldots \#w_2\#w_1,
    $$
    где $m$~--- фиксировано, а $w_i$~--- произвольные слова. Покажем, что если $m > \frac{k(k - 1)}{2}$,
    то язык $L$ не распознаётся автоматом с $k$ головками, а если это не так, то распознаётся.
    
    В каждом слове языка $L$ есть по два слова $w_i$. Будем называть их <<левым>> и <<правым>>
    соответственно. Пусть $m \leq \frac{k(k - 1)}{2}$. Опишем автомат с $k$ головками, который распознаёт
    язык $L$. Сначала все $k$ головок расположены на началах левых слов $w_1, w_2, \ldots,
    w_k$. Следующим действием последняя головка, которая стоит в начале $w_k$, доходит до начала правого
    слова $w_{k - 1}$. Далее проверяем равенство левых и правых слов $w_i$, где $1 \leq i \leq k -
    1$. Тем самым, <<потратив>> одну головку мы проверили равенство $k - 1$ слова сначала и с
    конца. Далее повторяем алгоритм для $k - 1$ головки и слова, без первых и последних $k - 1$ слов
    $w_i$. Тем самым мы проверим $(k - 1) + (k - 2) + \ldots + 1 = \frac{k(k - 1)}{2}$ слов. 
    
    Пусть теперь $m > \frac{k(k - 1)}{2}$. Посмотрим на левый и правый блоки с номером $\ell$ (слово
    $w_{\ell}$). Пусть в какой-то момент головки $i$ и $j$ стоят на разных копиях слова $w_l$. Тогда эта
    пара головок $(i, j)$ ни в какой другой момент времени не будет находиться в одинаковых словах $w_r$,
    при $r \neq \ell$, так как головки движутся только вправо. Тогда, так как $m > \frac{k(k - 1)}{2}$,
    то для какого-то слова $w_{\ell}$ верно, что в каждый момент времени только в одной копии $w_{\ell}$ может
    находиться головка. 
    
    Построим протокол, который будет запоминать состояния автомата и позиции головок для каждого такого
    момента, что либо какая-то головка оказалась в слове $w_{\ell}$, либо какая-то головка покинула слово
    $w_{\ell}$. Попробуем восстановить $w_{\ell}$ по протоколу. Подставим $x$ на место $w_{\ell}$. Если
    автомат выдал такой же протокол работы, то $x$ потенциально подходит. Предположим, что нашлось $2$
    подходящих слова $x$ и $y$, для которых протокол работает правильно. Тогда рассмотрим слово
    $w_{x, y}$, равное слову $w$, в котором левое слово $w_{\ell}$ заменили на $x$, а правое слово
    $w_{\ell}$ заменили на $y$. Заметим, что для слов $w$ и $w_{x, y}$ алгоритм работает одинаково. А
    значит $w_{x, y}$ лежит в нашем языке, что не правда. Откуда получаем противоречие, а значит по
    протоколу мы однозначно восстанавливаем $w_{\ell}$.
    
    Пусть длина слова $w$ равна $n$, и в нём зафиксированы слова $w_i, i \neq {\ell}$. Тогда размер
    протокола для $w$ равен $\bigO{k^3 \log n}$, где $k$~--- число головок. Осталось заметить, что 
    символов для кодирования строки $w$, с фиксированными $w_i, i \neq {\ell}$, не меньше, чем
    $\sum\limits_{i \neq \ell}{\abs{w_i}} + \bigO{k^3 \log n}$. Заметим, что существуют такие $w_i$, что
    $\abs{w_i} = s$ для любого $i$ и $K(w_1\#\ldots\#w_m\#w_m\#\ldots\#w_1) \geq ms - c$. Но из
    предыдущих рассуждений мы получили, что колмогоровская сложность $w$ равна $(m - 1)s +
    \bigO{\log s}$, так как $\sum\limits_{i \neq l} {\abs{w_i}} = (m - 1)s$. Тогда при больших $s$ мы
    получаем противоречие. А значит язык $L$ не лежит в $L_k$, теорема доказана.    
\end{proof}


\section{Случайные по Мартин-Лёфу}

Рассмотрим бесконечную строчку $w = x_1x_2x_3\ldots $ Хотим узнать, случайна ли эта строчка, или она
получена каким-то алгоритмом. Предположим, что мы знаем биты $x_1, x_2, \ldots, x_{n - 1}$. Можно ли узнать
бит $x_n$? Если бы можно было узнать все биты $x_n$ по предыдущим, то понятно, что строка не
случайная. Но как часто можно узнавать следующий бит по предыдущим в случайной строке? 

Хотелось бы сказать, что строка случайная, если существует такая константа $c$, что для любого $n$ верно
$\Kolm(x_{\leq n}) \geq n - c$ (то есть когда колмогоровская сложность достаточно большая). Оказывается,
что не существует такой последовательности $x_i$, для которой это неравенство выполнено.
\begin{theorem}
   Для любой последовательности $x_1x_2x_3\ldots$ и числа $n_0$ найдётся такое $n > n_0$, что
   $\Kolm(x_{\leq n}) \le n - \bigO{\log n}$. В частности, для любой константы $c$ найдётся такое $n$,
   что $\Kolm(x_{\leq n}) \le n - c$. 
\end{theorem}

\begin{proof}
    Рассмотрим любую последовательность $x_1x_2x_3\ldots$ и её префиксы $x_1\ldots x_kx_{k + 1}\ldots
    x_{k + m}, $ где $k + m = n$. Рассмотрим префиксы длины $n$, которые разбиваются на две части,
    $x_1\ldots x_k$ и $x_{k + 1} \ldots x_n$, причём $1x_1x_2\ldots x_k = m$ (не все $n$ подходят). Тогда
    $\Kolm(x_{\leq m + k}) \leq m + \bigO{1}$, так как зная последние $m$ символов префикса длины $n$ мы можем
    восстановить весь префикс. Но длина всего префикса равна $n = m + \log m$, откуда получаем, что
    $\Kolm(x_{\leq n}) \leq n - \bigO{\log n}$. Осталось заметить, что $n$ можно выбрать сколь угодно большое,
    что и доказывает теорему.
\end{proof}


\begin{definition}
    Функцию $F$ будем называть \deftext{беспрефиксной}, если из того, что $F$ определена на $x$ и $y$
    следует, что $x$ не является префиксом $y$, и наоборот.
\end{definition}

Для беспрефиксных функций можно определить понятие колмогоровской сложности так же, как и для обычных
функций. Мы будем обозначать её через $\KolmP(x)$.

\begin{definition}
   Строку $w$ будем называть \deftext{случайной}, если существует такая константа $c$, что
   $\KolmP(w_{\leq n}) \ge n - c$ для всех $n \in \mathbb{N}$.
\end{definition}

В определении колмогоровской сложности мы пользовались тем, что существует оптимальный способ описания
для беспрефиксных функций. Докажем это в следующей теореме.

\begin{theorem}
    Существует оптимальный беспрефиксный способ описания.
\end{theorem}

Для доказатетельства данной теоремы нам понадобится вспомогательное утверждение.

\begin{theorem}
    Cуществует такой алгоритм $A$, что для любой вычислимой функции $F$ выполняются условия:
    \begin{itemize}
        \item если $ F $ --- беспрефиксная, то $ A(F) = F $;
        \item если $ F $ --- не беспрефиксная, то $ A(F) = F' $, где $F'$ --- беспрефиксная.
    \end{itemize}
\end{theorem}

\begin{proof}
    Пусть на вход дана функция $F$, и мы хотим посчитать $F(x)$. Запустис $F$ параллельно на всех входах
    (стандартная операция из теории вычислимости). Если в какой-то момент, до того, как мы посчитали
    $F(x)$ оказалось, что алгоритм подсчета $F$ остановился двух строках $y$ и $yz$ для некоторых $y$ и
    $z$, то зацикливается. Иначе выдаем значение $F(x)$.

    Заметим, что если алгоритму $A$ дали на вход беспрефикснцю функцию, то алгоритм $A$ выдает ее же, и
    $A$ всегда выдаёт какую-то беспрефиксную функцию.
\end{proof}

\begin{proof}
    В качестве оптимального способа описания мы можем использовать $U'(x, y) \coloneqq A(x(y))$, где $(x,
    y)$ задано беспрефиксным образом, например все биты $x$ удваиваются, затем идет $01$, а затем
    кодировка $y$.
\end{proof}

Заметим, что $\KolmP(x) \le \Kolm(x) + 2 \log \Kolm(x) + \bigO{1}$. Чтобы доказать это неравенство
применим кодировку: $p \to a_1a_1a_2a_2 \ldots a_ka_k01p$, где $p$~--- описание $x$ и $\abs{p} =
a_1a_2\ldots a_k$. Тогда $k \leq \log \Kolm(x)$ и $\KolmP(x) \le \Kolm(x) + 2\log \Kolm(x) +
\bigO{1}$.

\begin{theorem}
    Мера Бернулли неслучайных последовательностей равна $0$. 
\end{theorem}

\begin{proof}
    Рассмотрим некоторую неслучайную последовательность $x_1x_2\ldots$. Тогда так как она не случайна, то
    для любого $c$ существуют $n_1,n_2, \ldots,n_l, \ldots$, что $\KolmP(x_{\leq n_i)} \leq n_i -
    c$. Тогда
    $$
        \sum\limits_{\{x \mid \KolmP(x) \le n - c, \abs{x} = n\}} 2^{-n} \leq
        \sum_x 2^{-\KolmP(x) - c} \le 2^{-c} \cdot \sum_x 2^{-\KolmP(x)} \le 2^{-c}.
    $$
    Последнее неравенство верно, так как код префиксный, и можно применить неравенство
    Крафта--Макмиллана. Также если $A_i$~--- множество строк с плохими префиксами $x_1x_2\ldots x_i$, то
    мера Бернулли неслучайных последовательностей
    $$
        M\left(\bigcup A_i\right) \leq \sum_{\{x \mid \KolmP(x) \le n - c\}} 2^{-n} < 2^{-c}.
    $$
    Осталось устремить $c$ к бесконечности, и получить требуемое.    
\end{proof}

\begin{theorem}[Закон больших чисел в форме Харди--Литлвуда]
    Для почти всех последовательностей $x \coloneqq  x_1x_2 \dots x_n \dots$ (с вероятностью $1$)
    выполнено:
    $$
        \left|\frac{x_1 + x_2 + \dots + x_n}{n} - \frac{1}{2}\right| =
        \bigO{\sqrt{\frac{\log n}{n}}}. 
    $$
\end{theorem}

\begin{proof}
    Пусть в $x_1 \dots x_n$ всего $p_n \cdot n$ единиц и $(1 - p_n) \cdot n$ нулей.
    $$
        \KolmP(x_1 \dots x_n) \le \Kolm(x_1 \dots x_n) + \bigO{\log n} \le \entropy(p) \cdot n +
        \bigO{\log n}.
    $$

    
    Пусть $p \coloneqq \frac{1}{2} + \delta_n$. Разложим $\entropy(p)$ в ряд в окрестности $\frac{1}{2}$:
    $$ 
        \entropy(1 / 2 + \delta_n) \cdot n = (1 - c_H \cdot \delta_n^2 + o(\delta_n^2)) \cdot n \le
        (1 - c'_H \cdot \delta_n^2) \cdot n.
    $$
    Таким образом для случайной последовательности (т.е. с вероятностью 1):
    $$
        n - c \le \KolmP(x_1 \dots x_n) \le n - c'_H \cdot \delta_n^2 \cdot n + \bigO{\log n}.
    $$

    Получаем, что $\delta_n^2 \le \bigO{\frac{\log n}{n}}$.
\end{proof}