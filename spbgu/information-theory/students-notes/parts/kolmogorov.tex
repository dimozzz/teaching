\section{Колмогоровская сложность}

\begin{definition}
    Пусть $F\colon \{0, 1\}^{*} \to \{0, 1\}^{*}$~--- вычислимая функция. \deftext{Сложностью описания}
    $x$ относительно  функции $F$ мы будем называть:
    $$
        \Kolm_F(x) = \min\{\abs{p} : F(p) = x\}.
    $$ 
    Если такого $p$ не найдётся, то $\Kolm_F(x) = +\infty$.
    
    Будем говорить, что способ описания $F$ \deftext{не хуже} способа описания $G$, и обозначать $F \prec
    G$ если существует такая константа $c_{FG}$, что для любого $x$ выполнено:
    $$
        \Kolm_F(x) \le \Kolm_G(x) + c_{FG}.
    $$

    Будем называть способ описания \deftext{оптимальным}, если он не хуже любого другого способа
    описания.
\end{definition}

\begin{theorem}
    Существует оптимальный способ описания.
\end{theorem}

\begin{proof}
    Доказательство оставим в качестве упражнения.
\end{proof}

Если $F, G$~--- оптимальные способы описания, то $\abs{\Kolm_F(x) - \Kolm_G(x)} \le c_{FG}$ для всех $x$
и некоторой константы $c_{FG}$.

\begin{definition}
    Будем называть \deftext{колмогоровской сложностью} $x$ число $\Kolm(x) \coloneqq \Kolm_u(x)$, где
    $u$~--- какой-то оптимальный способ описания.
\end{definition}

Мы не уточнили, какой из оптимальных способов описания рассматриваем, как следствие это означает, что мы
определили колмогоровскую сложность с точностью до аддитивной константы. Поэтому говорить о сложности
одной строки не имеет смысла (действительно, если взять конкретную строку $w$, то у нас существует
алгоритм, в тексте которого уже присутствует эта строка $w$, и он выписывает её на пустом входе). 
Чтобы данное определение обрело смысл, мы будем иметь ввиду, что у нас есть семейство строк,
параметризованное каким-либо параметром (чаще всего $n$).

Рассмотрим нетокоры простые свойства колмогоровской сложности.

\begin{enumerate}
    \item $K(x) \le |x| + c$;
    \item $K(xx) \le |x| + c$;
    \item если в слове $x$ длины $n$ не более $np$ единиц, то
        $$
            \Kolm(x) \le h(p) n + \bigO{1},
        $$ 
        где $h(p)$~--- энтропия нечестной монетки, выпадающей орлом с вероятностью $p$, где $0 \le p \le
        1$.
\end{enumerate}

Первое и второе утверждения следуют и того, что существует алгоритм, копирующий свой вход на выходную
ленту, а также алгоритм, который делает это дважды.

Рассмотрим множество $S$, состоящее их всех слов длины $n$, в которых не более $pn$ единиц. Заметим, что
$x \in S$, и его можно описать при помощи номера в этом множестве (подойдёт любая нумерация
элементов). Осталось заметить, что:
$$
    |S| \le \sum_{k = 1}^{np} \binom{n}{k} \leq 2^{h(p) n},
$$
где последнее неравенство следует из утверждения \ref{prop:binomial-coef}.


\begin{theorem}
    Рассмотрим такую всюду определенную функцию $M\colon \{0, 1\}^{*} \to \mathbb{N}$, что для любого $x
    \in \{0, 1\}^{*}$ верно $M(x) \le \Kolm(x)$. Если для любой константы $c$ существует такое
    $w \in \{0, 1\}^{*}$, что $M(w) > c$, то $M$~--- невычислима.
\end{theorem}

Хотим провести рассуждения, аналогичные рассуждениям в \textit{парадоксе Бэрри}: рассмотрим выражение
<<Наименьшее натуральное число, которое нельзя описать менее чем одиннадцатью русскими
словами>>. Поскольку слов конечное число, существует конечное множество фраз из менее чем одиннадцати
слов, и, следовательно, конечное подмножество натуральных чисел, определяемых фразой из одиннадцати
слов. Однако множество натуральных чисел бесконечно, следовательно, существуют числа, которые нельзя
определить фразой из менее чем одиннадцати слов. Среди них, существует наименьшее натуральное число
(наименьшее число можно выбрать из любого подмножества натуральных чисел), <<не описываемое менее чем
одиннадцатью словами>>. Но именно это число определяется приведённой выше фразой, и в ней менее
одиннадцати слов, а значит, оно не может являться искомым наименьшим числом и не может описываться данной
фразой. Возникает парадокс: должно существовать число, описываемое данной фразой, но поскольку выражение
само себе противоречит, не может существовать числа, им описываемого.
    
\begin{proof}
    Рассмотрим первое слово $x_c$, для которого выполняется условие $M(x_c) \ge c$ для некоторой
    константы $c$. Определим функцию $F(\overline{c}) = x_c,$ где $\overline{c}$~--- битовая запись числа
    $c$. Заметим, что если $M$ вычислима, то и функция $F$ будет вычислимой. Но тогда $\Kolm(x_c) \le
    \log c + c_0$, поскольку $\abs{\overline{c}} = \log c$, и мы получаем противоречие, так как
    $M(x_c) = c > \log c = \Kolm(x_c)$. 
\end{proof}

\begin{corollary}
    Любой оптимальный способ определим не всюду.
\end{corollary}

\begin{theorem}
    \label{th:99-words}
    $99\%$ слов $x \in \{0, 1\}^n$ имеют сложность $n - \bigO{1}$. 
\end{theorem}

\begin{proof}
    Зафиксируем какой-то оптимальный способ описания $U$. Тогда число описаний длины не более $n - c$ не
    превосходит $2^{n - c + 1}$. Тогда у хотя бы $2^{n} - 2^{n - c + 1}$ длина кратчайшего описания не
    менее $n - c + 1$, откуда нетрудно получить утверждение теоремы.  
\end{proof}


\subsection{Условная колмогоровская сложность}

Рассмотрим вычислимую функцию $F(p, y) = x$. Будем говорить, что
\deftext{сложность описания $x$ относительно функции $F$ при условии $y$} равна 
$$
    \Kolm_F(x \mid y) = \min\{\abs{p} : F(p, y) = x \}.
$$ 

\begin{theorem}
    Для любого $y$ существует оптимальный способ описания.
\end{theorem}

\begin{definition}
    Определим колмогоровскую сложность $\Kolm(x \mid y) = \Kolm_u(x \mid y)$ для некоторого оптимального
    способа описания $u$ при фиксированном $y$.
\end{definition}

Для условной колмогоровской сложности выполнены естественные свойства:
\begin{itemize}
    \item $\Kolm(x \mid y) < \Kolm(x) + \bigO{1}$;
    \item $\Kolm(f(x) \mid x) = \bigO{1}$ для любой вычислимой функции $f$.
\end{itemize}

\begin{definition}
    Определим колмогоровскую сложность пары $\Kolm(x, y) = \Kolm(\avg{x, y})$, где $\avg{x, y}$ ---
    фиксированная кодировка.
\end{definition}

Для энтропии мы знаем, что $h(x, y) = h(x) + h(y \mid x)$. Хочется доказать аналогичное утверждение про
колмогоровскую сложность. Равенство для колмогоровской сложности не всегда верно. Также неверно следующее
неравенство:  
$$
    \Kolm(x, y) \le \Kolm(x) + \Kolm(y \mid x) + \bigO{1}.
$$
    
Это можно видеть из следующего примера.
\begin{example}
    Рассмотрим пары $(x, y)$, для которых $|x| + |y| = n$. Таких пар $n \cdot 2^n$. Аналогично
    доказательству теоремы \ref{th:99-words} найдётся пара сложности $n + \log n - \bigO{1}$. Тогда для
    неё мы получим, что  
    $$
        \Kolm(x, y) = \Kolm(x) + \Kolm(y \mid x) + \log n + bigO{1}.
    $$
\end{example}

Мы момжет чуть-чуть поправить неравенство, чтобы оно стало верным.
\begin{theorem}
    $$
        \Kolm(x, y) \le \Kolm(x) + \Kolm(y \mid x) + \bigO{\log \Kolm(x, y)}.
    $$
\end{theorem}

\begin{proof}
    Пусть $n = n_1n_2\ldots n_k$~--- длина описания $x$. Тогда пару $\avg{x, y}$ можно закодировать
    числом:
    $$
        n_1n_1n_2n_2 \ldots n_kn_k01\{\text{описание } x\}\{\text{описание } y \text{ при известном $x$}\}.
    $$
    Что дает нам описание $(x, y)$ длины $\Kolm(x) + \Kolm(y \mid x) + \bigO{\log \Kolm(x, y)}$.
\end{proof}

\begin{theorem}[Колмогоров--Левин]
    Имеет место равенство 
    $$
        \Kolm(x, y) = \Kolm(x) + \Kolm(y \mid x) + \bigO{\log \Kolm(x, y)}.
    $$
\end{theorem}

\begin{proof}
    Неравенство в одну сторону мы показали. Докажем неравенство в другую сторону.
    
    Положим $n \coloneqq \Kolm(x, y)$. Определим множество $S \coloneqq \{(a, b) \mid \Kolm(a, b) \le n
    \}$. Будем рассматривать сечение $S_{x}$. Пусть $\log \abs{S_x} = m$. Тогда для описания $y$ по $x$
    нам нужно перечислить элементы $S_x$ и найти $y$. Для этого нам нужно знать $n$, это потребует
    $\bigO{\log n}$  битов, и нужно уметь перечислять элементы $S_x$, для этого нам потребуется $m$
    битов. Тогда:
    $$
        \Kolm(y \mid x) \le m + \bigO{\log n}.
    $$ 
    Для описания $x$ рассмотрим все такие $t$, что $\log \abs{S_t} \ge m$, и выберем из них $x$. Для
    этого нам опять потребуется $\log n$ битов, для хранения $n$, и $n - m$ битов для перечисления $t$,
    так как таких $t$ не больше, чем $\frac{\abs{S}}{2^m} \le 2^{n + 1 - m}$, так как $\abs{S} \le
    2^{n + 1}$. Откуда:
    $$
        \Kolm(x) \le n - m + \bigO{\log n}.
    $$ 
    Тогда получаем:
    $$
        \Kolm(x) + \Kolm(y \mid x) \le n + \bigO{\log n} = \Kolm(x, y) + \bigO{\log \Kolm(x, y)}
    $$
\end{proof}

Можно определить $I_{\Kolm}(x: y) = \Kolm(y) - \Kolm(y \mid x)$. Также верно неравенство 
$$
    \abs{I_{\Kolm}(x : y) - I_{\Kolm}(y : x)} \le \log \Kolm(x, y) + \bigO{1}.
$$ 
От логарифма избавиться не получится, можно рассмотреть такой $x \in \{0, 1\}^n$, что $\Kolm(x \mid n) =
n - \bigO{1}$. Тогда $I_{\Kolm}(n : x) = \bigO{1}$, а $I_{\Kolm}(x : n) = \log n$. 