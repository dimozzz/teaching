\input{../main.tex}

\setmathstyle{16.04.21}{Теория информации}{2 курс}


\begin{document}

\libproblem{inf-theory}{prefix-codes-2}
\libproblem{inf-theory}{triple-indep}


\begin{definition*}
    \deftext{Взаимной информацией} между случайными величинами $\alpha$ и $\beta$ будем называть функцию
    $I(\alpha : \beta) \coloneqq \entropy(\alpha) - \entropy(\alpha \mid \beta)$.

    Также определим взаимную информацию в $\alpha$ и $\beta$ при условии $\gamma$.
    $I(\alpha : \beta \mid \gamma) = \entropy(\alpha \mid \gamma) - \entropy(\alpha \mid \beta, \gamma)$.
\end{definition*}

\libproblem{inf-theory}{information-properties}
\libproblem{inf-theory}{entropy-2-dim}
\libproblem{inf-theory}{markov-entropy}
% \libproblem{inf-theory}{injective-code}
\libproblem{inf-theory}{stone-lift}
\libproblem{inf-theory}{entropy-counter}



\end{document}



%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% End:
