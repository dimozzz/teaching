\section{Недетерминированная коммуникация}

\subsection{Определения}

Пусть $f\colon X\times Y\to \{0, 1\}$. Мы хотим определить недетерминированную коммуникационную сложность
$f$.

\subsubsection{Первое определение}
Рассмотрим \emph{покрытия} матрицы $M_f$ прямоугольниками.

\begin{definition}
    $C^1(f)$~--- минимальное число $1$-прямоугольников, покрывающих все единицы $M_f$. $C^0(f)$~---
    минимальное число 0-прямоугольников, покрывающих все нули $M_f$.

    Недетерминированная коммуникационная сложность функции $f$~--- $\NCC{1}(f) = \ceil{\log C^1(f)}$.
\end{definition}

\subsubsection{Второе определение}
Три игрока: Алиса, Боб, Чарли. Чарли посылает Алисе и Бобу одинаковую подсказку $w$. Далее Алиса и Боб
общаются как обычно. Сложность: $|w| + \#(\text{переданных битов между Алисой и Бобом})$. Ответ <<1>>,
если существует подсказка $w$, для которой Алиса и Боб вычислят <<1>>. Ответ <<0>>, если для всех
подсказок они вычислят <<0>>.

Вопросы:
\begin{itemize}
    \item Может ли длина подсказки быть разной? Обычно мы фиксируем размер подсказки в протоколе.
    \item Может ли протокол зависеть от $w$? Может, но утверждается, что это ни на что не влияет~--- но
        мы это не обосновывали. Дальше будем считать, что протокол не зависит от $w$.
    \item Чарли знает $x$ и $y$? Это не важно, ведь у нас квантор существования по $w$.
\end{itemize}

Пример. $\mathcal{NE}(x, y) = \One_{x \neq y}$. Чарли посылает позицию различия. Алиса и Боб за два бита
проверяют. Сложность: $\log n + 2$.

Почему мы хотим платить за $w$? Пусть Чарли не платит. Тогда переделаем протокол так: Чарли теперь
посылает не просто $w$, а $(w, \ell)$, где $\ell$~--- лист протокола, в который приходили Алиса и Боб с
подсказкой $w$. Тогда Алиса и Боб смогут проверить такую подсказку всего за два бита~--- что каждый
приходит в такой лист. Таким образом, сложность любой функции будет не больше $2$, и определение теряет
смысл. (Или можно просто передать $(x, y)$ в качестве подсказки). 

\subsubsection{Третье определение}
Чарли посылает Алисе подсказку $w_x$, а Бобу~--- подсказку $w_y$. Далее Алиса и Боб общаются как
обычно. Сложность = $\#(\text{переданных битов между Алисой и Бобом})$, уже \emph{без платы} за
подсказки. Ответ <<1>>$\iff$ существует пара $(w_x, w_y)$, на которой Алиса и Боб выдадут <<1>>.

\subsubsection{Эквивалентность определений}
Покажем, что сложности в разных определениях совпадают с точностью до аддитивной константы. 

\paragraph{Def1$\implies$Def2.}
Чарли посылает номер прямоугольника из $C^1(f)$, далее Алиса и Боб проверяют, что оба его
пересекают. $\mathrm{Def}_2 \leq \mathrm{Def}_1 + 2$. 

\paragraph{Def2$\implies$Def1.}
Возможных подсказок $2^{|w|}$. Возможных пар (подсказка, лист с ответом 1) не более
$2^{|w|+\#\text{bits}}$. Каждой такой паре $(w, \ell)$ соответствует множество пар $A_{w, \ell} = (x,
y)$, которые на подсказке $w$ приходят в лист $\ell$. Заметим, что $x$ и $y$ можно проверять на
принадлежность $A_{w, \ell}$ независимо, поэтому $A_{w, \ell}$ является прямоугольником.

Так что прямоугольники $\{A_{w, \ell}\}$ образуют покрытие единиц матрицы $M_f$. $\mathrm{Def}_1 \le
\mathrm{Def}_2$. 

\paragraph{Def1$\implies$Def3.}
Чарли посылает номер прямоугольника из $C^1(f)$. Алиса посылает Бобу свою подсказку, чтобы тот проверил,
что они одинаковы, и они проверяют, что оба лежат в этом прямоугольнике (2 бита).
$\mathrm{Def}_3 \le \mathrm{Def}_1 + 2$.

\paragraph{Def3$\implies$Def1.}
Каждый 1-лист даёт прямоугольник в матрице $(X \times W_x) \times (Y \times W_y)$, их не более
$2^{\mathrm{Def}_3}$ штук. Спроецируем такие прямоугольники в $X \times Y$. Все единицы покрыты, ни в
какие нули не попадём. Получили, что $C^1(f) \le 2^{\mathrm{Def}_3}$. $\mathrm{Def}_1\le
\mathrm{Def}_3$.

\subsection{Классы коммуникационной сложности}

\begin{definition}
    $\P$~--- класс функций, имеющих детерминированную сложность $\polylog(n)$, то есть $\DCC(f) \le
    \polylog(n)$.

    $\NP$~--- класс функций, имеющих недетерминированную сложность $\polylog(n)$, то есть $\NCC{1}(f) \le
    \polylog(n)$.

    $\coNP$~--- класс функций, отрицания которых лежит в $\NP$, то есть $\NCC{0}(f) \le \polylog(n)$.
\end{definition}

\begin{remark}
    $\P = \NP \cap \coNP$.
\end{remark}

\begin{proof}
    В теореме~\ref{D < log C0 * log C1} мы доказали, что $\DCC(f) \le
    \bigO{\log C^0(f) \cdot \log C^1(f)}$. Так что $\DCC(f) \le \bigO{\NCC{0}(f) \NCC{1}(f)}$, поэтому
    если $\NCC{0} \le \polylog(n)$ и $\NCC{1} \le \polylog(n)$, то $\DCC \le \polylog(n)$. 
\end{proof}

\subsection{Rectangle Size для недетерминированной коммуникации}
Напомним, обычный принцип Rectangle Size (с мерой) утверждает, что если для любого прямоугольника $R$
выполняется $\mu(R) < \delta$, то $\DCC(f) \ge \log(1 / \delta)$. 

\begin{definition}
    Пусть $a$~--- какой-то цвет, $\mu$~--- мера, дающая единицу на всех клетках этого цвета.

    Определим $\RS^{\mu, a} = \max\limits_{a\text{-rect}} \mu(R)$.

    Тогда $\RS^a = \min\limits_{\mu} \RS^{\mu, a}$ по всем таким мерам.
\end{definition}

\begin{theorem}[Второе неравенство~--- Wigderson]
    $\frac{1}{\RS^a(f)} \le C^a(f) \le \bigO{\frac{n}{\RS^a(f)}}$.

    И, следовательно,
    $\log\left(\frac{1}{\RS^a(f)}\right) \le \NCC{a}(f) \le \log\left(\frac{1}{\RS^a(f)}\right) + \log n +
    c$.
\end{theorem}

\begin{proof}
    Первое неравенство очевидно.

    Пусть $\mu_1$~--- равномерная мера на $a$-элементах. Есть $a$-прямоугольник $R$ такой, что
    $\mu_1(R) \ge \RS^a(f)$ (по определению $\RS^a$). Возьмём этот прямоугольник в набор. Изменим
    меру. $\mu_2$~--- равномерная на непокрытых $a$-элементах. Повторим. Каждый раз покрываем хотя бы
    долю $\RS^a(f)$. Изначально $\le 2^{2n}$ клеток. Хотим, чтобы $2^{2n} (1 - \RS^a(f))^t < 1$.
    Выбирая $t = \frac{2n}{\RS^a(f)}$, получаем требуемое.
\end{proof}

Заметим, что мы получили покрытие, но не обязательно разбиение.

Можно ещё сказать так: если есть нижняя оценка на $\NCC{a}$, то есть мера, для которой Rectangle Size
маленький.

\subsection{Недетерминированная сложность \texorpdfstring{$\Disj^{\le k}_n$}{DISJ(n, <=k)}}

Можно ли улучшить оценку $\DCC(f) \le \bigO{\NCC{0}(f) \NCC{1}(f)}$? Нет, она точная. Рассмотрим
$\Disj^{\le k}_n$, где множества имеют размеры не больше $k$.

Эта функция является <<всюду определённой>> в том смысле, что множество корректных входов образуют
прямоугольник (то есть ограничения на вход Алисы и вход Боба независимы; иными словами, функцию можно
записать как $f\colon X \times Y \to \{0, 1\}$). Это хорошо, потому что некоторым теоремам это было нужно. 

\subsubsection{Верхняя оценка}

\begin{theorem}
    $\NCC{0}(\Disj^{\le k}_n) = \bigO{\log n}$.
\end{theorem}

\begin{proof}
    $\NCC{0}(\Disj^{\le k}_n) = \NCC{1}\left(\overline{\Disj^{\le k}_n}\right) = \bigO{\log n}$~--- общей
    подсказкой Чарли будет номер бита, в которой строки $x$ и $y$ пересекаются.
\end{proof}

\begin{theorem}
    $\NCC{1}(\Disj^{\le k}_n) \le \bigO{k + \log\log n}$.
\end{theorem}

\begin{proof}
    Наивно, без Чарли: $\bigO{k\log n}$~--- передать позиции $\le k$ единичек.

    Пусть теперь Чарли посылает множество-разделитель (сепаратор) $S$ такое, что $x \subseteq S$, а $y
    \cap S = \emptyset$. Проблема: потенциальных сепараторов слишком много, подсказка слишком
    большая. Так что выберем не слишком большое множество $Z$ потенциальных сепараторов, которые будут
    разделять любые два непересекающиеся множества размера $k$. Докажем, что такое множество $Z$
    существует, вероятностным методом.

    Выберем $\ell$ случайных сепараторов. Вероятность, что случайный сепаратор $S$ разделяет дизъюнктные
    $(x, y)$, не меньше $\frac{1}{2^{2k}}$. Вероятность, что существует пара $(x, y)$, что ни один из
    выбранных сепараторов не разделяет $(x, y)$, не больше
    $$
        \binom{n}{2k}\binom{2k}{k} \left(1 - \frac{1}{2^{2k}}\right)^{\ell} \le n^{2k} 2^{2k} \left(1 -
          \frac{1}{2^{2k}}\right)^{\ell} = (2n)^{2k} \cdot \left(1 - \frac{1}{2^{2k}}\right)^{\ell}.
    $$

    $\log((2n)^{2k}) = 2k\log(2n)$, поэтому, выбирая $\ell = 2^{2k} \cdot (2k \log(2n))$, мы получим, что
    вероятность меньше единицы. Тогда найдётся набор из $\ell$ сепараторов, разделяющих любую пару $(x,
    y)$.

    Теперь, чтобы передать номер одного из сепараторов, Чарли даёт подсказку из $\log \ell = 2k +
    \log(2k) + \log\log(2n) = \bigO{k + \log\log n}$ битов. 
\end{proof}

Пусть теперь $k = \log n$. Тогда $\NCC{0} = \bigO{\log n}$, $\NCC{1} = \bigO{\log n}$. Для доказательства
точности оценки осталось показать, что $\DCC(\Disj_n^{\le \log n}) = \Omega(\log^2 n)$. 