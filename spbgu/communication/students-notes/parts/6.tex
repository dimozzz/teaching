\subsection{Нижняя оценка}
\begin{theorem}
$\D(\DISJ^{\leqslant \log n}_n)\geqslant \Omega(\log^2 n)$.
\end{theorem}
\begin{proof}
$k = \log n$.
Обозначим множество множеств размера $\leqslant k$ за $Z_k$. $|Z_k| = \sum_{i=0}^k \binom{n}{i}$.
$M_{f}$ "--- матрица $|Z_k|\times |Z_k|$.
Ниже мы покажем, что эта матрица полного ранга, то есть ранга $|Z_k|$. Тогда $\D(f) \geqslant \log(2|Z_k| - 1) \geqslant \Omega(\log \binom{n}{k}) \ge \Omega(\log \left(\frac{n}{k}^k\right) = \Omega(k(\log n - \log k)) = \Omega(k\log n) = \Omega(\log^2 n)$.
\end{proof}

\begin{remark}
На самом деле, нам нужно только $\log k = o(\log n)$. При таком условии получаем $\D(\DISJ^{\leqslant k}_n)\geqslant \Omega(k\log n)$.
\end{remark}

\begin{theorem}[Разборов]
Для любого $k$ матрица $M_{\DISJ^{\leqslant k}_n}$ имеет полный ранг над $\mathbb{F}_2$.
\end{theorem}
\begin{proof}
Обозначим матрицу как $A$.
Нужно показать, что нет вектора-строки $\lambda$ такого, что $\lambda A = 0$.

Над $\mathbb{F}_2$ это значит, что сумма любого подмножества строк матрицы не равна нулю.

Введём формальные переменные $x_1, \ldots, x_n$.

Каждая строка матрицы $A$ соответствует множеству $S\subseteq [n]$ ($|S|\leqslant k$), сопоставим этой строке моном $\chi_S = \prod_{i\in S} x_i$.

Каждый столбец матрицы $A$ соответствует множеству $S\subseteq [n]$ ($|S|\leqslant k$), сопоставим этому столбцу полную подстановку $\rho_S$: $\rho_S(x_i) = 0$ для всех $i\in S$, для остальных $\rho_S(x_i) = 1$.

Рассмотрим клетку $(a, b)$. Покажем, что значение в этой клетке "--- это $\rho_b(\chi_a)$.
Если $a$ и $b$ не пересекаются, то все переменные монома $\chi_a$ будут присвоены $1$, поэтому значение после подстановки будет единицей.
Если пересекаются по $i$, то $\rho_b$ подставит в $x_i$ ноль, и переменная $x_i$ есть в $\chi_a$, поэтому $\rho_b(\chi_a)$ будет равно нулю.

Для вектора $\lambda$ определим $q_{\lambda} = \sum_{S\in Z_k} \lambda_S\cdot \chi_S$.

\begin{claim}
Пусть $\rho$ "--- подстановка с $\leqslant k$ нулями.
Множество её нулей обозначим как $T$ (то есть $\rho = \rho_T$).
Тогда $\rho(q_\lambda) = (\lambda A)_T$.
\end{claim}
\begin{proof}
$\rho_T(q_\lambda) = \sum_{S\in Z_k} \lambda_S\cdot \rho_T(\chi_S) = \sum_{S\in Z_k} \lambda_S\cdot A_{S, T} = (\lambda A)_T$.
\end{proof}

Осталось показать, что для любого ненулевого $\lambda$ найдётся $\rho$ с $\leqslant k$ нулями, что $\rho(q_\lambda)$ будет не нулём.

Пусть $S_0$ "--- наибольшее (по включению) множество, что $\lambda_{S_0} \neq 0$. Такое $S_0$ существует, так как $\lambda\neq 0$.

Определим частичную подстановку $\rho'$: $\rho'(x_i) = 1$ для всех $i\not\in S_0$.
Заметим, что $\rho'(q_\lambda)$ "--- ненулевой многочлен: член $\lambda_{S_0}\cdot \chi_{S_0}$ ни с чем не сократится ($\lambda_{S_0}\neq 0$; все $S\supsetneq S_0$ имеют нулевой коэффициент по максимальности $S_0$). Этот ненулевой многочлен мультилинеен, поэтому существует подстановка всех его переменных (которых не более $k$, так как $|S_0|\leqslant k$), обращающая его в не ноль: $\rho''(\rho'(q_\lambda)) \neq 0$.

Тогда определим подстановку $\rho = \rho''\circ \rho'$, у неё $\leqslant k$ нулей, что и требовалось.
\end{proof}

\chapter{Вероятностная коммуникация}
\section{Определения}
Чарли посылает случайные биты Алисе и Бобу. Далее они общаются детерминировано. Сложность протокола "--- это максимальное количество переданных между Алисой и Бобом битов.

Вычисляем функцию:
\begin{enumerate}[a)]
\item с двусторонней ошибкой: вероятность прийти в лист с правильным ответом не меньше $\frac{2}{3}$;
\item с односторонней ошибкой: один из ответов всегда верный, другой с вероятностью хотя бы. $\frac{1}{2}$.
\end{enumerate}

\subsection{Публичные случайные биты}
Чарли посылает одинаковые случайные биты Алисе и Бобу.

Два способа формализовать:
\begin{enumerate}
\item Также, как с приватными случайными битами (см. ниже), но гарантируется, что $r_1 = r_2$.
\item Задано распределение на детерминированных протоколах. Вначале Чарли выбирает из этого распределения протокол, а затем Алиса и Боб коммуницируют детерминировано (без случайных битов).
\end{enumerate}

Эти два определения эквивалентны, но мы этого не доказывали.

\subsection{Приватные случайные биты}
Чарли посылает независимые случайные строки $r_1$ и $r_2$, иначе говоря, у каждого игрока свой источник случайных битов. Протокол "--- дерево как в детерминированном случае, только функция в узле $v$ теперь либо $f_v(x, r_1)$, либо $f_v(y, r_2)$.

\section{Верхняя оценка для \texorpdfstring{$\EQ$}{EQ}}
По теореме~\ref{R-pub(EQ)} $\R^{pub}(\EQ) = \O(1)$.

\begin{theorem}
\label{R-pr(EQ)}
$\R^{pr}(\EQ) = \O(\log n)$
\end{theorem}
\begin{proof}
Пусть $z$ "--- формальная переменная.
Определим многочлены $p_x = \sum_i x_i z^i$, $p_y = \sum_i y_i z^i$. Строки равны $\iff$ $p_x = p_y$.

Пусть не равны. В большом поле $\mathbb{F}$ у нетривиального многочлена $(p_x-p_y)$ степени $\leqslant n$ в случайной точке будет не ноль с большой вероятностью: $\ge 1-\frac{n}{|\mathbb{F}|}$.

Пусть $|\mathbb{F}| \approx 3n$. Алиса посылает случайную точку в поле $\mathbb{F}$ и значение $p_x$ на этой точке. Боб сравнивает со своим значением. Итого $2\log |\mathbb{F}| + 1 = \O(\log n)$.
\end{proof}

\section{Связь между \texorpdfstring{$\D$}{D} и \texorpdfstring{$\R^{pub}$}{R[pub]}}
\begin{theorem}
$\D(f)\leqslant 2^{\R^{pr}_{\eps}(f)} (\log\left(\frac{1}{1/2-\eps}\right) + \R^{pr}_\eps(f))$.
\end{theorem}
\begin{corollary}
$\R^{pr}_\eps(\EQ) = \Theta(\log n)$.
\end{corollary}
\begin{proof}
Оценку снизу получаем из $\D(\EQ) = n + 1$ и данной теоремы.
Сверху оценили в теореме~\ref{R-pr(EQ)}.
\end{proof}

Заметим, что верхней оценки на $\D$ через $\R^{pub}$ быть не может: $\D(\EQ) = n + 1$, $\R^{pub}(\EQ) = \O(1)$.

\begin{proof}[Доказательство теоремы]
Пусть дан вероятностный протокол с приватными случайными битами, построим детерминированный.

Пусть даны $(x, y)$.
Посчитаем для каждого 1-листа вероятность, что мы в него придём. Если сумма вероятностей по листам $\ge \frac{1}{2}$, то вход принимается.
Проблема в том, что Алиса и Боб не знают $(x, y)$ "--- каждый знает только свой вход.

Алиса для каждого 1-листа $i$ самостоятельно считает вероятность того, что она сделает все шаги в верную сторону, обозначим её за $a_i$. Боб делает то же, это вероятности $b_i$.
Теперь им нужно проверить, что $\sum_i a_ib_i> 1 - \eps$, где сумма берётся по всем 1-листам, которых не более $2^{\R^{pr}_{\eps}(f)} $.

Просто пошлём вектор $\{a_i\}$ с некоторой точностью. Будем посылать первые $l = \log(\frac{1}{1/2 - \eps}) + \R^{pr}_{\eps}(f)$ битов каждого числа. Тогда ошибка в одном числе будет не больше $2^{-l} = \frac{1/2-\eps}{2^{\R^{pr}_{\eps}(f)}}$. Тогда суммарная ошибка не более $(1/2-\eps)$ "--- все $b_i$ посчитаны без погрешностей и их сумма от 0 до 1, поэтому просто сложили ошибки всех $a_i$.

Если $\sum a_ib_i> 1-\eps$, то $\sum a'_ib_i> 1-\eps - (\frac{1}{2} - \eps) = \frac{1}{2}$. Обратное тоже верно.
\end{proof}

\section{Связь между \texorpdfstring{$\R^{pub}$}{R[pub]} и \texorpdfstring{$\R^{pr}$}{R[pr]}}
Какой вообще зазор между сложностями с приватными и с публичными случайными битами?
\begin{proposition}
$\R^{pub}_{\eps}(f) \leqslant \R^{pr}_{\eps}(f)$.
\end{proposition}
Оказывается, от публичных битов можно избавиться, а зазор всегда не больше $\O(\log n)$.
\begin{theorem}[Ньюман]
$\R^{pr}_{2\eps}(f) \leqslant \R^{pub}_{\eps}(f) + \O(\log n)$. (Константа в $\O$ зависит от $\eps$.)
\end{theorem}
\begin{proof}
Алиса хотела бы просто послать свои приватные биты, а потом использовать имеющийся протокол. Однако, случайных битов может быть много.

Пусть мы используем не все возможные случайные публичные строки, а только строки $\vec r_1, \vec r_2, \ldots, \vec r_t$, тогда переслать достаточно номер такой строки, то есть $\log t$ битов.

Зафиксируем $t, x, y$.
Выберем $\vec r_1, \vec r_2, \ldots, \vec r_t$ случайно. $\vec r_i$ плохой, если с ним ответ неправильный.

$$\Pr_{\vec r_1, \ldots, \vec r_t}\left[\text{$\ge2\eps t$ штук из $\{\vec r_i\}$ плохие}\right] = \Pr\left[\sum_i \One_{\vec r_i\text{ плохой}} \ge 2\eps t\right]$$

Вероятность неверного ответа для каждого $\vec r_i$ исходного протокола $<\eps$, то есть $\E[\One_{\vec r_i\text{ плохой}}] < \eps$, и они выбираются независимо.
Тогда по неравенству Чернова $\Pr\left[\sum_i \One_{\vec r_i\text{ плохой}} \ge 2\eps t\right] \leqslant 2^{-1^2\eps t / c}$. Пусть $t = 2cn/\eps$, тогда вероятность меньше $2^{-2n}$.

Теперь применим union bound по всем возможным входам, получим $< 2^{2n}\times 2^{-2n} = 1$.
Значит, есть набор $\{\vec r_i\}$, для которого у всех входов ошибка не более $2\eps$.
\end{proof}

% (???) связь недетерминированной и рандомизированной сложности