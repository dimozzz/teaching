%2020-04-01

\section{Distributional protocols}

\subsection{Определения и свойства}

Пусть для каждого входа $(x, y)$ задана его вероятность $\mu(x, y)$. Distributional protocol~---
детерминированный протокол, который решает правильно задачу на всех входах, кроме доли, имеющей меру не
более $\varepsilon$. Сложность протокола $\DCC^{\mu}_{\varepsilon}(f)$~--- это высота дерева.

\begin{theorem}
    $\Rpub[\varepsilon](f) = \max\limits_{\mu} \DCC^{\mu}_{\varepsilon}(f)$.
\end{theorem}

\begin{proof}
    $\ge$: Для любого $\mu$ мы можем из $\RCC[\varepsilon]$ получить протокол: выберем наилучшие
    случайные биты. У них будет ошибка не более меры $\varepsilon$, иначе есть вход, у которого ошибка
    больше $\varepsilon$ в протоколе $\RCC[\varepsilon]$.

    $\le$. Пусть $c = \max\limits_{\mu} \DCC^{\mu}_{\varepsilon}(f)$. Будем использовать минимакс-теорему
    (формулировку см. ниже). Строки матрицы помечены всеми возможными входами $(x, y)$. Столбцы помечены
    всеми детерминированными протоколами сложности не более $c$. В клетке ставим $1$, если протокол верно
    работает на этом входе, и $0$ иначе.

    Рассмотрим распределение на входах $p$ и вероятностный протокол $\Pi$, являющийся распределением $q$
    на детерминированных протоколах. Тогда $p^TAq$~--- это вероятность верного ответа $\Pi$ на
    распределении на входах $p$.

    Мы знаем, что для любого распределения на входах $p$ найдётся даже детерминированный протокол с
    ошибкой не более $\varepsilon$, поэтому $\min\limits_p\max\limits_q p^TAq \ge 1 - \varepsilon$.

    По минимакс-теореме $\max\limits_q \min\limits_p p^TAq \ge 1 - \varepsilon$. То есть существует
    вероятностный протокол $\Pi$ такой, что какое бы распределение на входах не выбрать, вероятность
    верного ответа хотя бы $1 - \varepsilon$. Выбирая распределения, сконцентрированные на одном входе,
    получаем требуемое.
\end{proof}

\begin{theorem}[minimax, Neumann, \cite{Neumann28-minimax}]
    Пусть $A$~--- матрица, Алиса выбирает строку, Боб выбирает столбец, Алиса получает число денег,
    написанное в клетке на пересечении. Пусть теперь выбираем вероятности $p_i$ для строк и $q_j$ для
    столбцов. $\Exp[\text{выигрыш}] = p^TAq$. Тогда $\max\limits_{p} \min\limits_{q} p^TAq  =
    \min\limits_{q} \max\limits_{p} p^TAq$.
\end{theorem}

%\mycomment{\textcolor{red}{TODO: Добавить сюда комментарий про неправильную формулировку.}}

Нижние оценки на $\RCC(f)$ можно получать, выбирая распределение $\mu$ и доказывая нижнюю оценку. Все
известные нижние оценки на $\RCC(f)$, кроме лифтинга, так и устроены.


\subsection{Discrepancy}
Discrepancy~--- обобщение техники Rectangle Size. Пусть задано распределение на входах $\mu$.

\begin{definition}
    Discrepancy прямоугольника $R$~--- это $\disc_{\mu}(f, R) = \left|\mu(R \cap f^{-1}(0)) - \mu(R \cap
      f^{-1}(1)\right|$.

    Discrepancy функции $f$~--- это $\disc_{\mu}(f) = \max\limits_R \disc_{\mu}(f, R)$ по всем
    прямоугольникам $R$.
\end{definition}

\begin{theorem}
    $\DCC^\mu_{1 / 2 - \varepsilon}(f) = \Omega\left(\log\left(\frac{2
            \varepsilon}{\disc_{\mu}(f)}\right)\right)$.
\end{theorem}

\begin{proof}
    Рассмотрим прямоугольник $R_i$ листа $\ell_i$. Пусть вероятность ошибки этого листа есть
    $\mathrm{err}_i$ (она не больше $\mu(R_i) / 2$). Тогда $\disc(R_i) = (\mu(R_i) - \mathrm{err}_i) -
    \mathrm{err}_i = \mu(R_i) - 2\mathrm{err}_i$.

    Рассмотрим $\sum\limits_i \disc(R_i)$. С одной стороны, это $\sum (\mu(R_i) - 2 \mathrm{err}_i) = 1 -
    2 \mathrm{err} = 1 - 2 (1 / 2 - \varepsilon) = 2 \varepsilon$.

    С другой стороны, слагаемых в сумме $2^{\DCC(f)}$, у каждого $\disc$ не больше $\disc(f)$. Поэтому
    $2 \varepsilon \le 2^{\DCC(f)} \cdot \disc(f)$, откуда $\DCC(f) \ge \log\left(\frac{2
          \varepsilon}{\disc(f)}\right)$.

    %\mycomment{На лекции предлагалось посмотреть на большой прямоугольник в листе, но доказательство
    %было оставлено как упражнение. У меня не получилось реализовать этот план, оценка получается
    %слабее.}
\end{proof}

\begin{theorem}
    $\disc_{uni}(\IP) \le 2^{-n / 2}$.
\end{theorem}

\begin{proof}
    Рассмотрим $\pm 1$-матрицу $A$ для $\IP$. Рассмотрим прямоугольник $R = S \times T$. $\disc(\IP, R) =
    \left|\sum\limits_{(x, y) \in R} (-1)^{\avg{x, y}}\right| / 2^{2n}$.

    Числитель:
    $|\One^T_S \cdot A \cdot \One_T| \le \lVert A\rVert_2 \lVert \One_S\rVert_2 \lVert \One_T\rVert_2 \le
    \lVert A\rVert_2 \sqrt{|S||T|} = \lVert A\rVert_2 \sqrt{|R|}$.

    $A^2 = 2^{n} E$~--- проверили явно, см. второе доказательство
    теоремы~\ref{rk(M-IP) lower bound}. Поэтому $\lVert A^2\rVert_2 = 2^n$, и $\lVert
    A\rVert_2 = 2^{n / 2}$.

    Итого числитель $\le 2^{n / 2} \sqrt{|R|} \le 2^{3n / 2}$, что и требовалось доказать.
\end{proof}

Из этого получаем нижнюю оценку на $\RCC(\IP)$:

\begin{theorem}
    $\RCC(\IP) \ge \Omega(n)$.
\end{theorem}

Для $\Disj$ доказать нижнюю оценку таким способом не получится.

\begin{proposition}
    Для любого распределения $\mu$ $\disc_\mu(\Disj) \ge \frac{1}{2n} - \frac{1}{2n^2}$.
\end{proposition}

То есть нижняя оценка на коммуникацию получится разве что логарифмическая.

\begin{proof}
    Посмотрим на всю матрицу $M$. Пусть $\disc(\Disj, M) < \frac{1}{n}$. Тогда мера нулей хотя бы
    $\frac{1}{2} - \frac{1}{2n}$. Но у нулей есть покрытие $n$ $0$-прямоугольниками. Тогда какой-то из
    них имеет меру не менее $(\frac{1}{2} - \frac{1}{2n}) / n$ и такое же $\disc$.
\end{proof}

\begin{theorem}[Babai et al., \cite{BFS86-disj}]
    $\DCC^{uni}_{\varepsilon}(\Disj^{\le \sqrt{n}}_n) = \Omega(\sqrt{n})$.
\end{theorem}

\begin{proof}
    Пусть $\varepsilon < 1 / 100$. Будем рассматривать (почти 1)-прямоугольники. Пусть в прямоугольнике $S \times
    T$ не более $\varepsilon$ нулей. Покажем, что либо $\mu(S) \le 2^{-c\sqrt{n}}$, либо $\mu(T) \le 2^{-c\sqrt{n}}$.

(Продолжение в следующий раз.)
\end{proof}

Из этого получаем:

\begin{theorem}
    $\RCC(\Disj) = \Omega(\sqrt{n})$.
\end{theorem}

Для product-распределений это является и верхней оценкой.